{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Python for Research Homework: Week 3, Case Study 3\n",
    "\n",
    "In this case study, we will analyze a dataset consisting of an assortment of wines classified as \"high quality\" and \"low quality\" and will use k-Nearest Neighbors classification to determine whether or not other information about the wine helps us correctly guess whether a new wine will be of high quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT EDIT\n",
    "import numpy as np, random, scipy.stats as ss\n",
    "\n",
    "def majority_vote_fast(votes):\n",
    "    mode, count = ss.mstats.mode(votes)\n",
    "    return mode\n",
    "\n",
    "def distance(p1, p2):\n",
    "    return np.sqrt(np.sum(np.power(p2 - p1, 2)))\n",
    "\n",
    "def find_nearest_neighbors(p, points, k=5):\n",
    "    distances = np.zeros(points.shape[0])\n",
    "    for i in range(len(distances)):\n",
    "        distances[i] = distance(p, points[i])\n",
    "    ind = np.argsort(distances)\n",
    "    return ind[:k]\n",
    "\n",
    "def knn_predict(p, points, outcomes, k=5):\n",
    "    ind = find_nearest_neighbors(p, points, k)\n",
    "    return majority_vote_fast(outcomes[ind])[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Our first step is to import the dataset.\n",
    "\n",
    "#### Instructions \n",
    "- Read in the data as a pandas dataframe using `pd.read_csv`. The data can be found at https://courses.edx.org/asset-v1:HarvardX+PH526x+2T2019+type@asset+block@wine.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>color</th>\n",
       "      <th>high_quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>red</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>red</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0           0            7.4              0.70         0.00             1.9   \n",
       "1           1            7.8              0.88         0.00             2.6   \n",
       "2           2            7.8              0.76         0.04             2.3   \n",
       "3           3           11.2              0.28         0.56             1.9   \n",
       "4           4            7.4              0.70         0.00             1.9   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.076                 11.0                  34.0   0.9978  3.51   \n",
       "1      0.098                 25.0                  67.0   0.9968  3.20   \n",
       "2      0.092                 15.0                  54.0   0.9970  3.26   \n",
       "3      0.075                 17.0                  60.0   0.9980  3.16   \n",
       "4      0.076                 11.0                  34.0   0.9978  3.51   \n",
       "\n",
       "   sulphates  alcohol  quality color  high_quality  \n",
       "0       0.56      9.4        5   red             0  \n",
       "1       0.68      9.8        5   red             0  \n",
       "2       0.65      9.8        5   red             0  \n",
       "3       0.58      9.8        6   red             1  \n",
       "4       0.56      9.4        5   red             0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# write your code here!\n",
    "data = pd.read_csv(\"wine.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Next, we will inspect the dataset and perform some mild data cleaning.\n",
    "\n",
    "#### Instructions \n",
    "- In order to get all numeric data, we will change the `color` column to an `is_red` column. \n",
    "    - If `color == 'red'`, we will encode a `1` for `is_red`\n",
    "    - If `color == 'white'`, we will encode a `0` for `is_red`\n",
    "- Create this new column, `is_red`, and drop the `color` column\n",
    "- Store this all numeric data in a pandas dataframe called `numeric_data`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "      <th>high_quality</th>\n",
       "      <th>is_red</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  fixed acidity  volatile acidity  citric acid  residual sugar  \\\n",
       "0           0            7.4              0.70         0.00             1.9   \n",
       "1           1            7.8              0.88         0.00             2.6   \n",
       "2           2            7.8              0.76         0.04             2.3   \n",
       "3           3           11.2              0.28         0.56             1.9   \n",
       "4           4            7.4              0.70         0.00             1.9   \n",
       "\n",
       "   chlorides  free sulfur dioxide  total sulfur dioxide  density    pH  \\\n",
       "0      0.076                 11.0                  34.0   0.9978  3.51   \n",
       "1      0.098                 25.0                  67.0   0.9968  3.20   \n",
       "2      0.092                 15.0                  54.0   0.9970  3.26   \n",
       "3      0.075                 17.0                  60.0   0.9980  3.16   \n",
       "4      0.076                 11.0                  34.0   0.9978  3.51   \n",
       "\n",
       "   sulphates  alcohol  quality  high_quality  is_red  \n",
       "0       0.56      9.4        5             0     1.0  \n",
       "1       0.68      9.8        5             0     1.0  \n",
       "2       0.65      9.8        5             0     1.0  \n",
       "3       0.58      9.8        6             1     1.0  \n",
       "4       0.56      9.4        5             0     1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# write your code here!\n",
    "data.loc[data['color'] == 'red', 'is_red'] = 1\n",
    "data.loc[data['color'] == 'white', 'is_red'] = 0\n",
    "\n",
    "numeric_data=data.drop(['color'],axis=1)\n",
    "numeric_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1599.0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(numeric_data['is_red'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "We want to ensure that each variable contributes equally to the kNN classifier, so we will need to scale the data by subtracting the mean of each variable (column) and dividing each variable (column) by its standard deviation. Then, we will use principal components to take a linear snapshot of the data from several different angles, with each snapshot ordered by how well it aligns with variation in the data. In this exercise, we will scale the numeric data and extract the first two principal components.\n",
    "\n",
    "#### Instructions \n",
    "- Scale the data using the `sklearn.preprocessing` function `scale()` on `numeric_data`.\n",
    "- Convert this to a `pandas` dataframe, and store as `numeric_data`.\n",
    "    - Include the numeric variable names using the parameter `columns = numeric_data.columns`.\n",
    "- Use the `sklearn.decomposition` module `PCA()` and store it as `pca`.\n",
    "- Use the `fit_transform()` function to extract the first two principal components from the data, and store them as `principal_components`.\n",
    "- *Note*: You may get a `DataConversionWarning`, but you can safely ignore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.preprocessing as sp\n",
    "import pandas as pd\n",
    "scaled_data = sp.scale(numeric_data)\n",
    "numeric_data = pd.DataFrame(data=scaled_data, dtype=np.int8)\n",
    "\n",
    "import sklearn.decomposition as sd\n",
    "pca = sd.PCA(n_components = 2)\n",
    "principal_components = pca.fit_transform(numeric_data) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_data = np.array(numeric_data)\n",
    "numeric_data = (numeric_data - np.mean(numeric_data, axis=0)) / np.std(numeric_data, ddof=0 )\n",
    "\n",
    "import sklearn.decomposition\n",
    "pca = sklearn.decomposition.PCA(n_components=2)\n",
    "principal_components = pca.fit(numeric_data).transform(numeric_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "In this exercise, we will plot the first two principal components of the covariates in the dataset. The high and low quality wines will be colored using red and blue, respectively.\n",
    "\n",
    "#### Instructions \n",
    "- The first two principal components can be accessed using `principal_components[:,0]` and `principal_components[:,1]`. Store these as `x` and `y` respectively, and make a scatter plot of these first two principal components.\n",
    "- How well are the two groups of wines separated by the first two principal components?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6497, 2)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(principal_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEWCAYAAABmE+CbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14464895da0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "observation_colormap = ListedColormap(['red', 'blue'])\n",
    "x = principal_components[:,0]\n",
    "y = principal_components[:,1]\n",
    "\n",
    "plt.title(\"Principal Components of Wine\")\n",
    "plt.scatter(x, y, alpha = 0.2,\n",
    "    c = data['high_quality'], cmap = observation_colormap, edgecolors = 'none')\n",
    "plt.xlim(-8, 8); plt.ylim(-8, 8)\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig(\"graph.pdf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "In this exercise, we will create a function that calculates the accuracy between predictions and outcomes.\n",
    "\n",
    "#### Instructions\n",
    "- Create a function `accuracy(predictions, outcomes)` that takes two lists of the same size as arguments and returns a single number, which is the percentage of elements that are equal for the two lists.\n",
    "- Use accuracy to compare the percentage of similar elements in the `x` and `y` `numpy` arrays defined below.\n",
    "- Print your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51.5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "np.random.seed(1) # do not change\n",
    "\n",
    "x = np.random.randint(0, 2, 1000)\n",
    "y = np.random.randint(0 ,2, 1000)\n",
    "\n",
    "def accuracy(predictions, outcomes):\n",
    "    accuracy=0\n",
    "    for i in range(len(outcomes)):\n",
    "        if (predictions[i]==outcomes[i]):\n",
    "            accuracy +=1\n",
    "    \n",
    "    perc=accuracy/len(predictions)*100\n",
    "    return perc\n",
    "\n",
    "print(accuracy(x,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 6\n",
    "\n",
    "The dataset remains stored as data. Because most wines in the dataset are classified as low quality, one very simple classification rule is to predict that all wines are of low quality. In this exercise, we determine the accuracy of this simple rule. \n",
    "\n",
    "#### Instructions\n",
    "- Use `accuracy()` to calculate how many wines in the dataset are of low quality. Do this by using 0 as the first argument, and `data[\"high_quality\"]` as the second argument.\n",
    "- Print your result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.69385870401724\n"
     ]
    }
   ],
   "source": [
    "# write your code here!\n",
    "l1=np.zeros(len(data['high_quality']))\n",
    "print(accuracy(l1,data['high_quality']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 7 \n",
    "\n",
    "In this exercise, we will use the kNN classifier from `scikit-learn` to predict the quality of wines in our dataset.\n",
    "\n",
    "#### Instructions\n",
    "- Use `knn.predict(numeric_data)` to predict which wines are high and low quality and store the result as `library_predictions`.\n",
    "- Use `accuracy` to find the accuracy of your predictions, using `library_predictions` as the first argument and `data[\"high_quality\"]` as the second argument.\n",
    "- Print your answer. Is this prediction better than the simple classifier in Exercise 6?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.18762505771895\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "np.random.seed(123)\n",
    "knn = KNeighborsClassifier(n_neighbors = 10)\n",
    "knn.fit(numeric_data, data['high_quality'])\n",
    "# Enter your code here!\n",
    "library_predictions = knn.predict(numeric_data)\n",
    "print(accuracy(library_predictions,data['high_quality']))\n",
    "# print(100*np.mean(l1==data['high_quality']))\n",
    "# library_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 8\n",
    "\n",
    "Unlike the `scikit-learn` function, our homemade kNN classifier does not take any shortcuts in calculating which neighbors are closest to each observation, so it is likely too slow to carry out on the whole dataset. In this exercise, we will select a subset of our data to use in our homemade kNN classifier.\n",
    "\n",
    "#### Instructions \n",
    "- Fix the random generator using `random.seed(123)`, and select 10 rows from the dataset using `random.sample(range(n_rows), 10)`. Store this selection as `selection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4313, 1811, 3569, 940, 5402, 4111, 6452, 2561, 5997, 601]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "\n",
    "\n",
    "n_rows = data.shape[0]\n",
    "# Enter your code here.\n",
    "np.random.seed(123)\n",
    "selection = random.sample(range(n_rows),10)\n",
    "\n",
    "selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 9\n",
    "\n",
    "We are now ready to use our homemade kNN classifier and compare the accuracy of our results to the baseline.\n",
    "\n",
    "#### Instructions \n",
    "- For each predictor` p` in `predictors[selection]`, use `knn_predict(p, predictors[training_indices,:], outcomes, k=5)` to predict the quality of each wine in the prediction set, and store these predictions as a np.array called `my_predictions`. Note that knn_predict is already defined as in the Case 3 videos.\n",
    "- Using the `accuracy` function, compare these results to the selected rows from the `high_quality` variable in data using `my_predictions` as the first argument and `data.high_quality[selection]` as the second argument. Store these results as `percentage`.\n",
    "- Print your answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors = np.array(numeric_data)\n",
    "training_indices = [i for i in range(len(predictors)) if i not in selection]\n",
    "outcomes = np.array(data[\"high_quality\"])\n",
    "\n",
    "my_predictions = # Enter your code here!\n",
    "percentage = # Enter your code here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-795de2cf596d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmy_predictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mknn_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtraining_indices\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutcomes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mpredictors\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselection\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#percentage = # Enter your code here!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mpercentage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_predictions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhigh_quality\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mselection\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpercentage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-8-3d3a50b658fe>\u001b[0m in \u001b[0;36maccuracy\u001b[1;34m(predictions, outcomes)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0maccuracy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0moutcomes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m             \u001b[0maccuracy\u001b[0m \u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hp\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    599\u001b[0m         \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_apply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mis_scalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\hp\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py\u001b[0m in \u001b[0;36mget_value\u001b[1;34m(self, series, key)\u001b[0m\n\u001b[0;32m   2426\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2427\u001b[0m             return self._engine.get_value(s, k,\n\u001b[1;32m-> 2428\u001b[1;33m                                           tz=getattr(series.dtype, 'tz', None))\n\u001b[0m\u001b[0;32m   2429\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2430\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minferred_type\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'integer'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'boolean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas\\_libs\\index.c:4363)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_value (pandas\\_libs\\index.c:4046)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc (pandas\\_libs\\index.c:5085)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:13913)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.Int64HashTable.get_item (pandas\\_libs\\hashtable.c:13857)\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "predictors = np.array(numeric_data)\n",
    "training_indices = [i for i in range(len(predictors)) if i not in selection]\n",
    "outcomes = np.array(data[\"high_quality\"])\n",
    "\n",
    "#my_predictions = # Enter your code here!\n",
    "my_predictions = np.array([knn_predict(p, predictors[training_indices,:], outcomes, k=5) for p in predictors[selection]])\n",
    "#percentage = # Enter your code here!\n",
    "percentage = accuracy(my_predictions, data.high_quality[selection])\n",
    "print (percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
